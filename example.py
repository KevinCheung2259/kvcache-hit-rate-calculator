#!/usr/bin/env python3
"""
KVCacheå‘½ä¸­ç‡è®¡ç®—å™¨ä½¿ç”¨ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨KVCacheCalculatoræ¥åˆ†æä¸åŒé…ç½®ä¸‹çš„KVCacheæ€§èƒ½ã€‚
"""

from kvcache_calculator import (
    KVCacheCalculator, ModelConfig, SystemConfig, ConversationPattern,
    ModelDtype, KVCacheDtype
)
import json

def main():
    # åˆå§‹åŒ–è®¡ç®—å™¨
    calculator = KVCacheCalculator()
    
    print("ğŸš€ KVCacheå‘½ä¸­ç‡è®¡ç®—å™¨ç¤ºä¾‹")
    print("=" * 50)
    
    # ç¤ºä¾‹1: Llama2-7B é…ç½®
    print("\nğŸ“Š ç¤ºä¾‹1: Llama2-7B æ¨¡å‹é…ç½®")
    print("-" * 30)
    
    model_config = ModelConfig(
        num_layers=32,
        num_attention_heads=32,
        num_kv_heads=32,
        head_dim=128,
        model_dtype=ModelDtype.FP16,
        kvcache_dtype=KVCacheDtype.FP16,
        model_size_gb=14.0
    )
    
    system_config = SystemConfig(
        available_memory_gb=80.0
    )
    
    conv_pattern = ConversationPattern(
        avg_conversation_length=5.0,
        conversation_arrival_rate=2.0,
        within_conversation_interval=30.0,
        avg_sequence_length=100
    )
    
    # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    metrics = calculator.calculate_detailed_metrics(model_config, system_config, conv_pattern)
    print_metrics(metrics, "Llama2-7B")
    
    # ç¤ºä¾‹2: FP8ä¼˜åŒ–é…ç½®
    print("\nğŸ“Š ç¤ºä¾‹2: FP8ä¼˜åŒ–é…ç½® (èŠ‚çœå†…å­˜)")
    print("-" * 30)
    
    fp8_model_config = ModelConfig(
        num_layers=32,
        num_attention_heads=32,
        num_kv_heads=32,
        head_dim=128,
        model_dtype=ModelDtype.FP16,
        kvcache_dtype=KVCacheDtype.FP8,  # ä½¿ç”¨FP8æ¥èŠ‚çœå†…å­˜
        model_size_gb=14.0
    )
    
    fp8_metrics = calculator.calculate_detailed_metrics(fp8_model_config, system_config, conv_pattern)
    print_metrics(fp8_metrics, "FP8ä¼˜åŒ–")
    
    # æ¯”è¾ƒå†…å­˜æ•ˆç‡
    fp16_memory = calculator.calculate_kvcache_memory_per_token(model_config)
    fp8_memory = calculator.calculate_kvcache_memory_per_token(fp8_model_config)
    memory_saved = (fp16_memory - fp8_memory) / fp16_memory * 100
    
    print(f"\nğŸ’¾ å†…å­˜æ•ˆç‡å¯¹æ¯”:")
    print(f"  FP16 KVCache: {fp16_memory:,} å­—èŠ‚/Token")
    print(f"  FP8 KVCache:  {fp8_memory:,} å­—èŠ‚/Token")
    print(f"  å†…å­˜èŠ‚çœ:     {memory_saved:.1f}%")

def print_metrics(metrics, config_name):
    """æ‰“å°æ ¼å¼åŒ–çš„æŒ‡æ ‡ç»“æœ"""
    print(f"é…ç½®: {config_name}")
    print(f"  ğŸ“ˆ KVCacheå‘½ä¸­ç‡: {metrics['hit_rate']:.1%}")
    print(f"  ğŸ’¾ ç¼“å­˜åˆ©ç”¨ç‡: {metrics['cache_utilization']:.1%}")
    print(f"  âš¡ é¢„ä¼°å»¶è¿Ÿå‡å°‘: {metrics['estimated_latency_reduction']:.1%}")
    print(f"  ğŸ—‚ï¸ ç¼“å­˜å†…å­˜å ç”¨: {metrics['cache_memory_gb']:.2f} GB")
    print(f"  ğŸ”¢ æ¯Tokenå†…å­˜: {metrics['memory_per_token_bytes']:.0f} å­—èŠ‚")
    print(f"  ğŸ’¬ å¯ç¼“å­˜ä¼šè¯æ•°: {metrics['avg_cached_conversations']:.1f}")
    print(f"  ğŸ¯ ç¼“å­˜å‘½ä¸­æ¬¡æ•°/ç§’: {metrics['cache_hits_per_second']:.1f}")

if __name__ == "__main__":
    main() 